\chapter{Crypto Currency}
\section{Smart Things}
The idea of smart objects are that you would have economic agents which
are objects. An example would be cars. A car might be blockchain aware
and could lock itself up and be unlockable by one bitcoin address
and then be only unlockable by another address based on a particular
bitcoin transaction. This solves the important security problem that one might
move the bitcoins but there is no guarantee the other party will relinquish
their property.

You might also develop secure hardware as intermediaries to trade bitcoins
so that way you can have features like reversable transactions built on
top of bitcoins.  The secure hardware aspect would allow independent and 
trustless verification.

\section{Papers}

\section{Decentralized Authentication}

\section{Secure, Privacy-Preserving Speech Technologies}


\subsection{A framework for secure speech recognition}

In \cite{smaragdis2007framework} the authors make use of several
partially homomorphic protocols for doing several speech tasks:
\begin{enumerate}
\item secure inner products: they use \cite{verykios2004state}
\item secure maximum index:`
\end{enumerae}

\subsection{Privacy-preserving speaker verification and identification using Gaussian mixture models}
In \cite{pathak2013privacy} the author addresses the question of whether we can do speaker verficiation
(authentication) and identification in a privacy-preserving and secure manner such that the 
verifier/identifier does not have access to the actual recording of speech but can still successfully
run the programs.  Speaker identification involves finding individuals through audio surveillance
and such technologies have the application that one can find somebody among a crowd of individuals
without violating the voice privacy of anybody else.  Speaker verification is about letting users
authenticate themselves.  The privacy and security attacks in speaker verification are particularly
dangerous because it could allow an adversary to imitate the speaker and break into other systems.

The solution proposed is based on secure multiparty computation protocols that allows the system
to operate only encrypted speech data without observing the plaintext.  There is a client-server
model where the user executes a client program on a network coupled with a public key cryptosystem.
The user retains the private key and shares the public key with the system.


Speaker identification works by estimating a universal background model over all speakers which is then adapted to an individuals voice when they enroll in the system using MAP adaptation.  Verification
is performed by testing a query speaker with a log-likelihood
ratio test of the MAP adapted hypothesized speaker model
against the background model.  Open set speaker identification
is performed by simply finding which of the speaker models
is accepted or whether the background model fits the input
speech best.

Partially homomorphic encryption schemes are used: in particular
Paillier and Boneh-Goh-Nissim (BGN) so that we can compute inner
products.  Paillier can compute an encrypted inner product where
one of the vectors is plaintext and the other is encrypted
but it can't compute inner products between two encrypted vectors.
BGN can compute encrypted inner products, however.  Due to these
limitations Paillier is better served for interactive protocols
with Alice and Bob both doing computations on their respective
machines, whereas BGN can be used for non-interactive protocols.

\subsubsection{Adversarial Model}

The parties are assumed to be interactin in a client-server
framework where they are separate.

The threat models used are semi-honest and malicious behavior.
In semi-honest behavior the protocol is followed but all
intermediate results are kept so that one party can
attempt to learn as much as possible about the other party.

The system is not supposed to ever have access to the user's
speech so the user submits an encrypted adapted speaker model
during the enrollment phase and encrypted speech during the 
verification phase.  The assumption is that the system
provides the algorithm honestly since incorrect output
would be a potential system security breach 
(or a user frustration) but not necessarily
reveal any private information. Thus, the system is assumed
to be semi-honest.

In the private enrollment protocol the user has samples
$x_1,\ldots, x_n$, encryption key $E[\cdot]$, and decryption key $E^{-1}[\cdot]$.
The system has a universal background model $\lambda_U=W_i^U$
for $i=1,\ldots,N$ where taking a special inner product with
each of the $W_i^U$ and using the mixing weights using the protocol
for secure inner products from \cite{pathak2011privacy}
we can compute the likelihood of the data under the UBM.  The system
also has access to the encryption key $E[\cdot]$.

The output is that the system ends up with an encrypted user
model $E[\lambda_s]=E[\hat{W}^s_i]$ for $i=1,\ldots,N$.  The steps
are
\begin{enumerate}
\item User performs the model adaptation of $\lambda_U$
with $x_1,\ldots,x_n$ to obtain $\lambda_s$
\item User encodes $\lambda_s$ into the matrix representation
\item User encrypts $\hat{W}_i$ and sends to the system
\end{enumerate}

The authors then present two potential implementations of the
verification protocol: a non-interactive version and an interactive
version.
